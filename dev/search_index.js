var documenterSearchIndex = {"docs":
[{"location":"api.html#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api.html#QARBoM.train!","page":"API Reference","title":"QARBoM.train!","text":"train!(\n    rbm::AbstractRBM,\n    x_train,\n    ::Type{PCD};\n    n_epochs::Int,\n    batch_size::Int,\n    learning_rate::Vector{Float64},\n    metrics::Vector{<:EvaluationMethod} = [MeanSquaredError],\n    early_stopping::Bool = false,\n    store_best_rbm::Bool = true,\n    patience::Int = 10,\n    stopping_metric::Type{<:EvaluationMethod} = MeanSquaredError,\n    x_test_dataset = nothing,\n    y_test_dataset = nothing,\n    file_path = \"pcd_metrics.csv\",\n)\n\nTrain an RBM using the Persistent Contrastive Divergence (PCD) algorithm.\n\nArguments\n\nrbm::AbstractRBM: The RBM to train.\nx_train: The training data.\nn_epochs::Int: The number of epochs to train the RBM.\nbatch_size::Int: The size of the mini-batches.\nlearning_rate::Vector{Float64}: The learning rate for each epoch.\nmetrics::Vector{<:EvaluationMethod}: The evaluation metrics to use.\nearly_stopping::Bool: Whether to use early stopping.\nstopping_metric::Type{<:EvaluationMethod}: The metric to use for early stopping.\nstore_best_rbm::Bool: Whether to store the rbm with the best stopping_metric.\npatience::Int: The number of epochs to wait before stopping.\npatience::Int: The number of epochs to wait before stopping.\nx_test_dataset: The test data to evaluate the model. If not set the training data will be used.\nfile_path: The file path to store the metrics.\n\n\n\n\n\ntrain!(\n    rbm::Union{RBMClassifier, GRBMClassifier},\n    x_train,\n    label_train,\n    ::Type{PCD};\n    n_epochs::Int,\n    batch_size::Int,\n    learning_rate::Vector{Float64},\n    label_learning_rate::Vector{Float64},\n    metrics::Vector{<:EvaluationMethod} = [Accuracy],\n    early_stopping::Bool = false,\n    store_best_rbm::Bool = true,\n    patience::Int = 10,\nstopping_metric::Type{<:EvaluationMethod} = Accuracy,\n    x_test_dataset = nothing,\n    y_test_dataset = nothing,\n    file_path = \"pcd_classifier_metrics.csv\",\n)\n\nTrain an RBM classifier using the Persistent Contrastive Divergence (PCD) algorithm.\n\nArguments\n\nrbm::RBMClassifier: The RBM classifier to train.\nx_train: The training data.\nlabel_train: The training labels.\nn_epochs::Int: The number of epochs to train the RBM.\nbatch_size::Int: The size of the mini-batches.\nlearning_rate::Vector{Float64}: The learning rate for each epoch.\nlabel_learning_rate::Vector{Float64}: The learning rate for the labels for each epoch.\nmetrics::Vector{<:EvaluationMethod}: The evaluation metrics to use.\nearly_stopping::Bool: Whether to use early stopping.\nstopping_metric::Type{<:EvaluationMethod}: The metric to use for early stopping.\nstore_best_rbm::Bool: Whether to store the rbm with the best stopping_metric.\npatience::Int: The number of epochs to wait before stopping.\npatience::Int: The number of epochs to wait before stopping.\nx_test_dataset: The test data to evaluate the model. If not set the training data will be used.\ny_test_dataset: The test labels to evaluate the model. If not set the training labels will be used.\nfile_path: The file path to store the metrics.\n\n\n\n\n\ntrain!(\n    rbm::AbstractRBM,\n    x_train,\n    ::Type{FastPCD};\n    n_epochs::Int,\n    gibbs_steps::Int = 1,\n    batch_size::Int,\n    learning_rate::Vector{Float64},\n    fast_learning_rate::Float64,\n    metrics::Vector{<:DataType} = [MeanSquaredError],\n    early_stopping::Bool = false,\n    store_best_rbm::Bool = true,\n    patience::Int = 10,\n    stopping_metric::Type{<:EvaluationMethod} = MeanSquaredError,\n    x_test_dataset = nothing,\n    file_path = \"fast_pcd_metrics.csv\",\n)\n\nTrain an RBM using Fast Persistent Contrastive Divergence (FastPCD) algorithm.\n\nTieleman and Hinton (2009) \"Using fast weights to improve persistent contrastive divergence\"\n\nArguments\n\nrbm::AbstractRBM: The RBM to train.\nx_train: The training data.\nn_epochs::Int: The number of epochs to train the RBM.\ngibbs_steps::Int: The number of Gibbs Sampling steps to use.\nbatch_size::Int: The size of the mini-batches.\nlearning_rate::Vector{Float64}: The learning rate for each epoch.\nfast_learning_rate::Float64: The fast learning rate.\nmetrics::Vector{<:EvaluationMethod}: The evaluation metrics to use.\nearly_stopping::Bool: Whether to use early stopping.\nstopping_metric::Type{<:EvaluationMethod}: The metric to use for early stopping.\nstore_best_rbm::Bool: Whether to store the rbm with the best stopping_metric.\npatience::Int: The number of epochs to wait before stopping.\nx_test_dataset: The test data.\nfile_path: The file path to save the metrics.\n\n\n\n\n\ntrain!(\n    rbm::Union{RBMClassifier, GRBMClassifier},\n    x_train,\n    label_train,\n    ::Type{FastPCD};\n    n_epochs::Int,\n    gibbs_steps::Int = 1,\n    batch_size::Int,\n    learning_rate::Vector{Float64},\n    fast_learning_rate::Float64,\n    label_learning_rate::Vector{Float64},\n    metrics::Vector{<:DataType} = [Accuracy],\n    early_stopping::Bool = false,\n    store_best_rbm::Bool = true,\n    patience::Int = 10,\n    stopping_metric::Type{<:EvaluationMethod} = Accuracy,\n    x_test_dataset = nothing,\n    y_test_dataset = nothing,\n    file_path = \"fast_pcd_classifier_metrics.csv\",\n)\n\nTrain an RBM using Fast Persistent Contrastive Divergence (FastPCD) algorithm.\n\nTieleman and Hinton (2009) \"Using fast weights to improve persistent contrastive divergence\"\n\nArguments\n\nrbm::RBMClassifier: The RBM to train.\nx_train: The training data.\nlabel_train: The training labels.\nn_epochs::Int: The number of epochs to train the RBM.\ngibbs_steps::Int: The number of Gibbs Sampling steps to use.\nbatch_size::Int: The size of the mini-batches.\nlearning_rate::Vector{Float64}: The learning rate for each epoch.\nfast_learning_rate::Float64: The fast learning rate.\nlabel_learning_rate::Vector{Float64}: The label learning rate for each epoch.\nfast_label_learning_rate::Float64: The fast label learning rate.\nmetrics::Vector{<:EvaluationMethod}: The evaluation metrics to use.\nearly_stopping::Bool: Whether to use early stopping.\nstopping_metric::Type{<:EvaluationMethod}: The metric to use for early stopping.\nstore_best_rbm::Bool: Whether to store the rbm with the best stopping_metric.\npatience::Int: The number of epochs to wait before stopping.\nx_test_dataset: The test data.\ny_test_dataset: The test labels.\nfile_path: The file path to save the metrics.\n\n\n\n\n\ntrain!(\n    rbm::RBMClassifiers,\n    x_train,\n    label_train,\n    ::Type{QSampling};\n    n_epochs::Int,\n    gibbs_steps::Int,\n    batch_size::Int,\n    learning_rate::Vector{Float64},\n    label_learning_rate::Vector{Float64},\n    metrics::Vector{<:DataType} = [Accuracy],\n    early_stopping::Bool = false,\n    store_best_rbm::Bool = true,\n    patience::Int = 10,\n    stopping_metric::Type{<:EvaluationMethod} = Accuracy,\n    x_test_dataset = nothing,\n    y_test_dataset = nothing,\n    file_path = \"qsamp_classifier_metrics.csv\",\n    model_setup::Function,\n    sampler,\n    kwargs...,\n)\n\nTrain an RBMClassifier using Quantum sampling.\n\nArguments\n\nrbm::RBMClassifier: The RBM classifier to train.\nx_train: The training data.\nlabel_train: The training labels.\nn_epochs::Int: The number of epochs to train the RBM.\ngibbs_steps::Int: The number of Gibbs steps to use.\nbatch_size::Int: The size of the mini-batches.\nlearning_rate::Vector{Float64}: The learning rate for each epoch.\nlabel_learning_rate::Vector{Float64}: The learning rate for the labels for each epoch.\nmetrics::Vector{<:EvaluationMethod}: The evaluation metrics to use.\nearly_stopping::Bool: Whether to use early stopping.\nstopping_metric::Type{<:EvaluationMethod}: The metric to use for early stopping.\nstore_best_rbm::Bool: Whether to store the rbm with the best stopping_metric.\npatience::Int: The number of epochs to wait before stopping.\nx_test_dataset: The test data to evaluate the model. If not set the training data will be used.\ny_test_dataset: The test labels to evaluate the model. If not set the training labels will be used.\nfile_path: The file path to store the metrics.\nhandle_error::Function: The function to handle errors during training.\nmodel_setup::Function: The function to setup the QUBO sampler.\nsampler: The QUBO sampler to use.\nkwargs...: Additional arguments for the QUBO sampler\nmax_visible::Vector{Float64}: The maximum value for the visible nodes.\nmin_visible::Vector{Float64}: The minimum value for the visible nodes.\nnum_evaluated_states::Int: The top N quantum-sampled states to be considered for update.\nvariable_encoding_tolerance::Float64: Custom tolerance for the variable encoding\n\n\n\n\n\n","category":"function"},{"location":"manual/getting_started.html#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"This guide will help you get started with QARBoM.jl, a Julia package for training Restricted Boltzmann Machines (RBMs) using various methods, including classical and quantum approaches.","category":"page"},{"location":"manual/getting_started.html#Defining-Your-Dataset-and-RBM","page":"Getting Started","title":"Defining Your Dataset and RBM","text":"","category":"section"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"To begin, you need a dataset and an RBM model. The dataset should be a Vector{Vector{<:Number}}, where each inner vector represents a sample.","category":"page"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"using QARBoM\n\n# Define your dataset\ntrain_data = MY_DATA_TRAIN\ntest_data = MY_DATA_TEST\n\n# Create an RBM with 10 visible nodes and 5 hidden nodes\nrbm = RBM(10, 5)","category":"page"},{"location":"manual/getting_started.html#Training-RBM-Using-Contrastive-Divergence","page":"Getting Started","title":"Training RBM Using Contrastive Divergence","text":"","category":"section"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"Contrastive Divergence (CD) is a common method for training RBMs. Below is an example of how to train your RBM using CD:","category":"page"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"N_EPOCHS = 100\nBATCH_SIZE = 10\n\nQARBoM.train!(\n    rbm, \n    train_data,\n    CD; \n    n_epochs = N_EPOCHS,  \n    gibbs_steps = 3, \n    learning_rate = [0.0001/(j^0.8) for j in 1:N_EPOCHS], \n    metrics = [MeanSquaredError], \n    x_test_dataset = test_data,\n    early_stopping = true,\n    file_path = \"my_cd_metrics.csv\",\n)","category":"page"},{"location":"manual/getting_started.html#Training-RBM-Using-Persistent-Contrastive-Divergence","page":"Getting Started","title":"Training RBM Using Persistent Contrastive Divergence","text":"","category":"section"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"Persistent Contrastive Divergence (PCD) is an alternative training method that maintains a persistent chain of Gibbs samples.","category":"page"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"QARBoM.train!(\n    rbm, \n    train_data,\n    PCD; \n    n_epochs = N_EPOCHS, \n    batch_size = BATCH_SIZE, \n    learning_rate = [0.0001/(j^0.8) for j in 1:N_EPOCHS], \n    metrics = [MeanSquaredError], \n    x_test_dataset = test_data,\n    early_stopping = true,\n    file_path = \"my_pcd_metrics.csv\",\n)","category":"page"},{"location":"manual/getting_started.html#Training-RBM-Using-Quantum-Sampling","page":"Getting Started","title":"Training RBM Using Quantum Sampling","text":"","category":"section"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"Quantum Sampling leverages quantum annealers for training RBMs. Below is an example setup using the DWave package:","category":"page"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"using DWave\n\n# Define a setup for your quantum sampler\nMOI = QARBoM.ToQUBO.MOI\nMOI.supports(::DWave.Neal.Optimizer, ::MOI.ObjectiveSense) = true\n\nfunction setup_dwave(model, sampler)\n  MOI.set(model, MOI.RawOptimizerAttribute(\"num_reads\"), 25)\n  MOI.set(model, MOI.RawOptimizerAttribute(\"num_sweeps\"), 100)\nend\n\nQARBoM.train!(\n    rbm, \n    train_data,\n    QSampling; \n    n_epochs = N_EPOCHS, \n    batch_size = 5, \n    learning_rate = [0.0001/(j^0.8) for j in 1:N_EPOCHS], \n    x_test_dataset = test_data,\n    early_stopping = true,\n    file_path = \"qubo_train.csv\",\n    model_setup = setup_dwave,\n    sampler = DWave.Neal.Optimizer,\n)","category":"page"},{"location":"manual/getting_started.html#RBM-for-Classification","page":"Getting Started","title":"RBM for Classification","text":"","category":"section"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"For classification tasks, you can use the RBMClassifier, which includes label nodes in its architecture.","category":"page"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"rbm = RBMClassifier(\n    10, # number of visible nodes\n    5,  # number of hidden nodes\n    2,  # number of label nodes\n)\n\nQARBoM.train!(\n    rbm, \n    train_data,\n    y_train,\n    PCD; \n    n_epochs = N_EPOCHS, \n    batch_size = BATCH_SIZE, \n    learning_rate = [0.0001/(j^0.8) for j in 1:N_EPOCHS], \n    label_learning_rate = [0.001/(j^0.6) for j in 1:N_EPOCHS], \n    metrics = [Accuracy],\n    x_test_dataset = test_data,\n    y_test_dataset = y_test,\n    early_stopping = true,\n    file_path = \"my_pcd_metrics_classification.csv\",\n)","category":"page"},{"location":"manual/getting_started.html#Non-Binary-Visible-Nodes","page":"Getting Started","title":"Non-Binary Visible Nodes","text":"","category":"section"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"QARBoM.jl supports continuous visible nodes. Ensure your dataset is normalized to have zero mean and unit variance, as recommended by Hinton's guide.","category":"page"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"For quantum sampling with continuous visible nodes, you need to define the maximum and minimum values for each visible node:","category":"page"},{"location":"manual/getting_started.html","page":"Getting Started","title":"Getting Started","text":"QARBoM.train!(\n    rbm, \n    train_data,\n    label_train_data,\n    QSampling; \n    n_epochs = N_EPOCHS, \n    batch_size = 5, \n    learning_rate = [0.0001/(j^0.8) for j in 1:N_EPOCHS], \n    label_learning_rate = [0.0001/(j^0.8) for j in 1:N_EPOCHS], \n    metrics = [Accuracy],\n    x_test_dataset = test_data,\n    y_test_dataset = label_test_data,\n    early_stopping = true,\n    file_path = \"qubo_train.csv\",\n    model_setup = setup_dwave,\n    sampler = DWave.Neal.Optimizer,\n    max_visible = max_visible, \n    min_visible = min_visible\n)","category":"page"},{"location":"index.html#QARBoM.jl","page":"Home","title":"QARBoM.jl","text":"","category":"section"},{"location":"index.html#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"QARBoM.jl, a platform for benchmarking quantum-assisted against classical training of Restricted Boltzmann Machines (RBMs). Recent works have been testing the training of RBMs using quantum sampling techniques, such as Quantum Annealing, and comparing their results against classical methods. However, these projects are mainly limited to a specific dataset and only one RBM classical training procedure to compare. With that said, QARBoM.jl establishes an agnostic benchmarking framework where, with minor code adjustments, one can select over different training algorithms~(classical or quantum-assisted) and parameters to model integer or real-valued datasets, expediting the research endeavor on the applications of Quantum Computing for RBMs. ","category":"page"},{"location":"index.html#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"index.html","page":"Home","title":"Home","text":"QARBoM is avaible through Julia's General Registry:","category":"page"},{"location":"index.html","page":"Home","title":"Home","text":"julia> import Pkg\n\njulia> Pkg.add(\"https://github.com/NITeQ/QARBoM.jl\")\n\njulia> using QARBoM","category":"page"},{"location":"assets/README.html#QARBoM.jl's-Assets","page":"QARBoM.jl's Assets","title":"QARBoM.jl's Assets","text":"","category":"section"},{"location":"assets/README.html#logo","page":"QARBoM.jl's Assets","title":"Logo","text":"","category":"section"},{"location":"assets/README.html","page":"QARBoM.jl's Assets","title":"QARBoM.jl's Assets","text":"(Image: QARBoM.jl Logo)","category":"page"},{"location":"assets/README.html#Colors","page":"QARBoM.jl's Assets","title":"Colors","text":"","category":"section"},{"location":"assets/README.html","page":"QARBoM.jl's Assets","title":"QARBoM.jl's Assets","text":"The colors were chosen according to  Julia's Reference for logo graphics¹.","category":"page"},{"location":"assets/README.html#Typography","page":"QARBoM.jl's Assets","title":"Typography","text":"","category":"section"},{"location":"assets/README.html","page":"QARBoM.jl's Assets","title":"QARBoM.jl's Assets","text":"<a href=\"#1\">¹</a> github.com/JuliaLang/julia-logo-graphics","category":"page"}]
}
