Last login: Fri Jun  7 10:30:17 on ttys003
pripper@Pedros-MacBook-Pro ~ % cd Documents/GitHub/RBM 
pripper@Pedros-MacBook-Pro RBM % julia --proj=example
The latest version of Julia in the `1.10` channel is 1.10.4+0.x64.apple.darwin14. You currently have `1.10.3+0.x64.apple.darwin14` installed. Run:

  juliaup update

in your terminal shell to install Julia 1.10.4+0.x64.apple.darwin14 and update the `1.10` channel to that version.
               _
   _       _ _(_)_     |  Documentation: https://docs.julialang.org
  (_)     | (_) (_)    |
   _ _   _| |_  __ _   |  Type "?" for help, "]?" for Pkg help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 1.10.3 (2024-04-30)
 _/ |\__'_|_|_|\__'_|  |  Official https://julialang.org/ release
|__/                   |

julia> using Revise

julia> using QARBoM, DataFrames, CSV, DWave
Precompiling QARBoM
  1 dependency successfully precompiled in 6 seconds. 112 already precompiled.

julia> rbm = QARBoM.BernoulliRBM(22,10)
BernoulliRBM([2.5035335319008003 -0.6051291288144612 … -1.1231036221072999 -0.6762620113091834; -0.09374911691864089 -0.42887981223695043 … -0.9750586253661787 -0.8483752221365108; … ; -0.19844359965284755 0.929974468059492 … -0.3201594628491713 0.009001669616913191; -0.19982032073485723 0.9611914599156687 … 1.1587993112577324 -0.007864122886505284], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 22, 10)

julia> rbm.W
22×10 Matrix{Float64}:
  2.50353    -0.605129   -0.168978   …  -0.118574  -1.1231     -0.676262
 -0.0937491  -0.42888     0.728497      -1.34924   -0.975059   -0.848375
 -0.71243    -0.916746    2.27466       -1.80904   -1.01448     0.949469
  0.401287   -0.0140842   1.27166       -1.37453   -0.99367    -0.292182
  0.284598    0.1183     -0.775702       0.406742  -0.0963328   0.0203161
  1.06809     2.66005    -2.74232    …   1.151      0.414535    3.34322
 -0.873777   -1.05694     0.272691       0.372346   2.01188     0.0777149
 -0.888261   -0.0447674   0.0299506      1.87105   -0.047342   -1.88674
  0.908412   -2.22865    -1.06432       -0.455829  -0.112358   -0.747039
  1.15656    -0.522942   -0.735044       0.18867    1.37869    -1.25965
  ⋮                                  ⋱                         
 -0.424432   -0.940528    0.334313       0.327782  -0.352633   -0.514663
 -0.303472   -0.90137    -0.0628239      1.19071   -0.605509   -0.892841
  1.54344    -1.31784    -0.268549   …   0.597695  -1.19549    -0.0424562
 -1.93235     0.911992    0.505449      -0.190321  -1.4929     -0.166344
  1.47334     0.880412    0.220052      -0.863864   1.05356     0.960888
  2.21374     0.782104    0.220476       2.42501    1.50675     2.57476
 -1.36004    -1.19688    -0.203668       0.576579  -1.01604    -0.18828
 -0.198444    0.929974   -0.70876    …   0.472067  -0.320159    0.00900167
 -0.19982     0.961191    0.534977      -0.0239     1.1588     -0.00786412

julia> print(rbm.W)
[2.5035335319008003 -0.6051291288144612 -0.1689777218679678 -0.9139229376292596 -0.040210961009068756 -0.8177789403820881 -1.4387284906035316 -0.11857440768683825 -1.1231036221072999 -0.6762620113091834; -0.09374911691864089 -0.42887981223695043 0.7284972184218675 -0.5670675387158921 0.4167812789732578 -1.5034475118200252 0.9886423898547138 -1.3492365338096244 -0.9750586253661787 -0.8483752221365108; -0.7124302649181368 -0.9167458676376371 2.27465958300614 -0.3032869000938818 -0.18772956846782105 -1.3197127550731036 0.05388676128262615 -1.8090394436392712 -1.0144835155668872 0.9494694186986945; 0.40128723498023444 -0.014084228668655743 1.2716602721419956 -0.9496233115289402 1.4082939719346939 -0.3874304876255929 1.8989409039174776 -1.3745261126856585 -0.9936702313252165 -0.292182064847596; 0.2845984260313545 0.11830021119016007 -0.7757015494761601 1.7071711186968213 -0.7536088314908342 1.9021524469946451 -0.30828491580772593 0.4067420668129639 -0.09633277326280011 0.020316073441156785; 1.0680893116108516 2.660046775251759 -2.7423199895696024 -0.5507438469823729 -0.25137953840767724 -0.2815206218326772 -1.6277312243777011 1.1509955021959797 0.4145348653352118 3.3432201247183664; -0.8737773019904281 -1.056944601887192 0.27269095339178046 0.2985355825572091 2.190549061928218 0.2831634002505407 -0.30999121880830766 0.3723458564897622 2.0118795912737277 0.07771493515557008; -0.8882606274300494 -0.044767409919365495 0.02995063759375047 0.5565480311787793 1.3728530764367048 0.22695066925810886 -0.41772208032587876 1.8710479542474547 -0.04734203599247947 -1.8867372958285409; 0.9084124168648856 -2.228651043649622 -1.0643176249510853 -0.8007436507284191 0.3606469802838978 0.09426944596013466 -0.3129565621241593 -0.4558288073492155 -0.11235836508914612 -0.7470391253456309; 1.1565552274263406 -0.5229422654414112 -0.7350435524831478 -1.0053991489285745 0.10434701963893228 -0.5013587533184336 -0.054385799167590995 0.18866990931032254 1.378690215467587 -1.2596513792048074; 1.4439855585477606 -0.43323493675081565 0.8231218963685216 1.4212259634551225 1.3544331358943218 -0.9705344725556788 0.0015979201868454812 1.228928893560495 -0.6913731322534932 0.4153989968217154; -0.28737252203804564 -0.28278400795859104 1.2411208526105046 1.5522494262634479 1.1388339167211166 -2.5563606982064595 0.24549503930971311 0.09219441260781733 0.33668351394788665 -0.9772842755857244; -0.03589602272954692 0.7567103977508356 -1.7190902969358945 0.03769854052186348 1.7050963711605847 -0.628951168998809 -0.2615952891615254 -0.23987242286688942 0.16167924395683467 -0.5437006990832643; -0.4244315207459674 -0.9405275119609682 0.33431300001664666 0.43420138681892334 0.06010088460481125 1.7223248768609787 -0.1862024622702879 0.32778236128618266 -0.3526329061068121 -0.5146633272778592; -0.3034718621639237 -0.9013703243861266 -0.06282393336525369 0.953620020011297 -1.3599504751226126 -0.11180829178816622 0.46805649789671583 1.1907073417972058 -0.6055094354910646 -0.8928413952165593; 1.5434440708949488 -1.3178377906455692 -0.26854854518833454 2.321942501959965 0.02264940403032524 -1.080762331323439 0.3137691749230393 0.5976947488702328 -1.1954882383535514 -0.04245618319532059; -1.9323517034030346 0.9119918655975101 0.5054491468823874 -0.6706980880689968 0.06931777431379808 -1.5418734383045059 0.6895096945091985 -0.19032098687857843 -1.492901610698006 -0.16634366975408368; 1.4733408930566771 0.8804119329290305 0.22005236525828634 0.2961912515516666 -0.007360219577377495 -0.5276997834969669 -1.0648328437469612 -0.8638639749426833 1.0535591828318407 0.9608882773748826; 2.2137394883328616 0.7821040495206021 0.22047631000810133 -0.35430557227589266 -0.8555229651867147 -0.9686125635058093 1.369597014821592 2.425005905964767 1.5067511278066357 2.574758256926067; -1.360042045537602 -1.1968771724743157 -0.20366772891038631 1.1185873384224911 0.781443253652957 0.5837040210101603 -0.3143927111516672 0.5765788590577331 -1.0160449725294358 -0.1882798481434755; -0.19844359965284755 0.929974468059492 -0.7087603133655928 -1.5957905935882442 1.0668019903504116 -0.4647758405744614 -0.40392335169590865 0.4720673527581623 -0.3201594628491713 0.009001669616913191; -0.19982032073485723 0.9611914599156687 0.5349774547531345 1.185749244318892 -0.7536302391175147 0.438866371576281 -0.7468105442623214 -0.023899980197250762 1.1587993112577324 -0.007864122886505284]
julia> df = DataFrame(CSV.File(raw"./example/converted_bool_only.csv"))

246022×22 DataFrame
    Row │ AlcoholDrinkers  BlindOrVisionDifficulty  ChestScan  DeafOrHardOfHearing  DifficultyConcentrating  DifficultyDressingBathing  DifficultyErrands  DifficultyWalking  FluVaxLast12  HIVTesting  HadAngina  HadArthritis  HadAsthma  HadCOPD  HadDepressiveDisorder  HadHeartAttack  HadKidneyDisease  HadSkinCancer  ⋯
        │ Int64            Int64                    Int64      Int64                Int64                    Int64                      Int64              Int64              Int64         Int64       Int64      Int64         Int64      Int64    Int64                  Int64           Int64             Int64          ⋯
────────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
      1 │               0                        0          0                    0                        0                          0                  0                  0             1           0          0             1          0        0                      0               0                 0              0  ⋯
      2 │               0                        0          0                    0                        0                          0                  0                  0             1           0          0             1          0        0                      0               0                 0              0
      3 │               1                        1          1                    0                        0                          0                  0                  1             0           0          0             1          0        0                      0               0                 0              0
      4 │               0                        0          0                    0                        0                          0                  0                  1             1           0          0             1          0        0                      1               0                 0              1
      5 │               0                        0          0                    0                        0                          0                  0                  0             1           0          0             1          0        0                      0               0                 0              0  ⋯
      6 │               1                        0          1                    0                        0                          0                  0                  0             1           1          0             0          0        0                      0               0                 0              0
      7 │               0                        0          1                    0                        0                          0                  0                  0             1           0          0             0          0        0                      0               0                 0              0
      8 │               0                        0          1                    0                        0                          0                  0                  0             1           1          1             1          0        0                      0               1                 0              1
      9 │               0                        0          1                    1                        0                          0                  0                  0             0           0          0             1          0        0                      0               0                 0              0  ⋯
     10 │               0                        0          1                    0                        0                          0                  0                  0             1           0          0             1          1        0                      0               0                 0              1
     11 │               1                        0          1                    0                        0                          0                  0                  0             1           0          0             0          0        0                      0               0                 0              0
     12 │               0                        0          0                    0                        0                          0                  0                  1             0           0          0             1          0        0                      0               0                 0              0
     13 │               0                        0          1                    0                        1                          0                  0                  1             1           0          0             1          0        0                      0               1                 0              1  ⋯
     14 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
     15 │               0                        0          1                    1                        1                          1                  0                  1             1           0          1             1          0        0                      1               0                 1              0
     16 │               0                        0          1                    0                        0                          0                  0                  0             1           0          0             0          0        0                      1               0                 0              0
     17 │               0                        0          1                    0                        0                          0                  0                  0             1           0          0             0          1        0                      0               0                 0              0  ⋯
     18 │               1                        0          1                    0                        0                          0                  0                  1             1           0          0             0          0        0                      0               0                 0              0
     19 │               0                        0          0                    0                        0                          0                  0                  0             1           0          0             0          0        0                      0               0                 0              0
     20 │               0                        0          0                    0                        1                          1                  1                  1             1           0          0             1          0        0                      0               0                 1              1
     21 │               0                        0          1                    1                        1                          0                  0                  0             1           0          1             1          0        1                      1               0                 0              0  ⋯
     22 │               0                        0          1                    1                        1                          1                  1                  1             1           0          0             1          0        0                      0               0                 0              0
     23 │               1                        0          1                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              1
     24 │               1                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
     25 │               0                        1          1                    0                        0                          1                  1                  0             1           0          1             1          0        0                      0               0                 0              0  ⋯
     26 │               0                        0          1                    0                        0                          0                  0                  0             1           1          0             1          0        1                      0               0                 0              0
     27 │               0                        0          1                    1                        1                          0                  0                  0             1           0          0             1          0        0                      0               0                 0              0
     28 │               1                        0          0                    0                        0                          0                  0                  0             1           1          0             1          0        0                      0               0                 0              1
     29 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0  ⋯
     30 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             1          0        0                      0               0                 0              0
     31 │               1                        1          0                    0                        0                          0                  0                  1             0           1          0             1          0        1                      1               0                 0              0
     32 │               0                        0          1                    0                        0                          0                  1                  1             1           0          0             1          0        1                      0               0                 0              0
   ⋮    │        ⋮                    ⋮                 ⋮               ⋮                      ⋮                         ⋮                      ⋮                  ⋮               ⋮            ⋮           ⋮           ⋮            ⋮         ⋮               ⋮                  ⋮                ⋮                ⋮        ⋱
 245992 │               0                        0          0                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0  ⋯
 245993 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
 245994 │               1                        0          1                    0                        0                          0                  0                  1             1           1          0             1          0        0                      1               0                 1              0
 245995 │               0                        0          0                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0
 245996 │               1                        0          1                    0                        0                          0                  0                  0             1           0          0             1          1        0                      1               0                 0              0  ⋯
 245997 │               1                        0          0                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0
 245998 │               1                        0          0                    0                        0                          0                  0                  0             0           1          0             1          0        0                      0               0                 0              0
 245999 │               1                        0          1                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0
 246000 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             1          0        0                      0               0                 0              0  ⋯
 246001 │               1                        0          1                    0                        0                          0                  1                  0             0           1          0             0          0        0                      1               0                 0              0
 246002 │               1                        0          1                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0
 246003 │               1                        0          1                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
 246004 │               1                        0          0                    0                        0                          0                  0                  0             1           1          0             0          0        0                      0               0                 0              1  ⋯
 246005 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             1          0        0                      0               0                 0              0
 246006 │               1                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
 246007 │               0                        0          1                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
 246008 │               1                        0          0                    0                        1                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0  ⋯
 246009 │               0                        0          1                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
 246010 │               0                        0          0                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0
 246011 │               1                        0          0                    0                        0                          0                  0                  0             0           1          0             1          0        0                      0               0                 0              0
 246012 │               0                        0          0                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0  ⋯
 246013 │               1                        0          1                    1                        0                          0                  0                  0             0           1          1             0          0        0                      0               1                 0              0
 246014 │               1                        0          0                    0                        1                          0                  1                  0             0           0          0             0          0        0                      1               0                 0              0
 246015 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
 246016 │               1                        0          0                    0                        0                          0                  0                  0             0           1          0             0          0        0                      0               0                 0              0  ⋯
 246017 │               1                        0          1                    0                        0                          0                  0                  0             1           1          0             0          0        0                      0               1                 0              0
 246018 │               1                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      0               0                 0              0
 246019 │               0                        0          0                    0                        0                          0                  0                  0             0           0          0             0          0        0                      1               0                 0              0
 246020 │               1                        0          0                    0                        0                          0                  0                  0             1           1          0             1          0        0                      0               0                 0              0  ⋯
 246021 │               0                        0          0                    0                        0                          0                  0                  0             1           1          0             0          0        0                      0               0                 0              0
 246022 │               0                        0          1                    0                        0                          0                  0                  0             1           1          0             0          1        0                      0               1                 0              0
                                                                                                                                                                                                                                                                                             4 columns and 245959 rows omitted

julia> x_train = Vector{Vector{Int}}()
Vector{Int64}[]

julia> for row in eachrow(df)
           push!(x_train, collect(row))
       end

julia> 

julia> avg_loss = QARBoM.train_pcd(rbm, x_train[1:10000]; batch_size = 10, n_epochs = 50, learning_rate = 0.01)
Setting mini-batches
Starting training
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     1 |    2.3364 |        0.0337 |       0.0611 |        0.0136 |    0.1083 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     2 |    1.9571 |        0.0259 |       0.0397 |        0.0151 |    0.1890 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     3 |    1.9467 |        0.0119 |       0.0428 |        0.0094 |    0.2532 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     4 |    1.9472 |        0.0126 |       0.0332 |        0.0097 |    0.3086 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     5 |    1.9427 |        0.0127 |       0.0439 |        0.0103 |    0.3756 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     6 |    1.9335 |        0.0120 |       0.0434 |        0.0102 |    0.4411 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     7 |    1.9294 |        0.0117 |       0.0324 |        0.0198 |    0.5050 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     8 |    1.9266 |        0.0118 |       0.0428 |        0.0095 |    0.5691 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     9 |    1.9245 |        0.0120 |       0.0430 |        0.0100 |    0.6341 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    10 |    1.9184 |        0.0118 |       0.0435 |        0.0102 |    0.6996 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    11 |    1.9088 |        0.0119 |       0.0325 |        0.0210 |    0.7650 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    12 |    1.9041 |        0.0122 |       0.0426 |        0.0202 |    0.8399 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    13 |    1.9023 |        0.0119 |       0.0430 |        0.0097 |    0.9046 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    14 |    1.8927 |        0.0224 |       0.0432 |        0.0100 |    0.9802 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    15 |    1.8903 |        0.0122 |       0.0325 |        0.0099 |    1.0348 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    16 |    1.8942 |        0.0125 |       0.0431 |        0.0207 |    1.1111 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    17 |    1.8882 |        0.0119 |       0.0428 |        0.0212 |    1.1870 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    18 |    1.8875 |        0.0221 |       0.0428 |        0.0099 |    1.2619 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    19 |    1.8838 |        0.0123 |       0.0328 |        0.0200 |    1.3269 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    20 |    1.8843 |        0.0121 |       0.0438 |        0.0099 |    1.3927 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    21 |    1.8788 |        0.0123 |       0.0435 |        0.0098 |    1.4583 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    22 |    1.8752 |        0.0121 |       0.0439 |        0.0195 |    1.5338 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    23 |    1.8837 |        0.0228 |       0.0333 |        0.0099 |    1.5997 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    24 |    1.8686 |        0.0119 |       0.0330 |        0.0098 |    1.6544 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    25 |    1.8671 |        0.0115 |       0.0431 |        0.0097 |    1.7187 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    26 |    1.8692 |        0.0118 |       0.0438 |        0.0100 |    1.7842 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    27 |    1.8536 |        0.0117 |       0.0329 |        0.0097 |    1.8385 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    28 |    1.8538 |        0.0122 |       0.0331 |        0.0309 |    1.9147 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    29 |    1.8533 |        0.0117 |       0.0433 |        0.0100 |    1.9797 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    30 |    1.8540 |        0.0124 |       0.0433 |        0.0207 |    2.0562 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    31 |    1.8505 |        0.0219 |       0.0445 |        0.0100 |    2.1326 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    32 |    1.8459 |        0.0117 |       0.0333 |        0.0099 |    2.1876 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    33 |    1.8486 |        0.0115 |       0.0327 |        0.0097 |    2.2414 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    34 |    1.8466 |        0.0118 |       0.0328 |        0.0212 |    2.3073 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    35 |    1.8432 |        0.0124 |       0.0335 |        0.0208 |    2.3739 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    36 |    1.8438 |        0.0119 |       0.0431 |        0.0204 |    2.4495 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    37 |    1.8416 |        0.0234 |       0.0430 |        0.0097 |    2.5256 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    38 |    1.8422 |        0.0121 |       0.0428 |        0.0098 |    2.5903 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    39 |    1.8395 |        0.0123 |       0.0432 |        0.0100 |    2.6559 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    40 |    1.8390 |        0.0119 |       0.0424 |        0.0099 |    2.7200 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    41 |    1.8404 |        0.0124 |       0.0437 |        0.0196 |    2.7957 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    42 |    1.8380 |        0.0116 |       0.0432 |        0.0098 |    2.8603 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    43 |    1.8310 |        0.0121 |       0.0327 |        0.0100 |    2.9151 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    44 |    1.8288 |        0.0126 |       0.0332 |        0.0207 |    2.9816 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    45 |    1.8233 |        0.0121 |       0.0428 |        0.0096 |    3.0460 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    46 |    1.8226 |        0.0124 |       0.0448 |        0.0102 |    3.1135 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    47 |    1.8232 |        0.0118 |       0.0426 |        0.0097 |    3.1775 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    48 |    1.8197 |        0.0233 |       0.0437 |        0.0101 |    3.2547 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    49 |    1.8219 |        0.0127 |       0.0337 |        0.0106 |    3.3116 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Gibbs) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    50 |    1.8152 |        0.0222 |       0.0331 |        0.0101 |    3.3770 |
|------------------------------------------------------------------------------|
Finished training after 50 epochs.
Total time spent sampling: 0.7121989727020264
Total time spent in Gibbs sampling: 2.002925157546997
Total time spent updating parameters: 0.6618695259094238
Total time spent training: 3.3769936561584473
50-element Vector{Float64}:
 2.3363701643016137
 1.957080884237994
 1.9466574627264999
 1.9472063077818125
 1.9427275291694648
 1.9334948717704301
 1.929423233218661
 1.9265777893174492
 1.9245353281829822
 1.9184007384741577
 1.9088200882244968
 1.904109909842754
 1.9023044455170794
 1.8927414724170535
 1.8902816536244875
 1.8942376051001568
 1.8881968170525834
 1.8874635323941478
 1.8837606321668188
 1.8842711605444984
 1.8787709505795007
 1.875159234600697
 1.8836627869658211
 1.8685926468489535
 1.8671245178785907
 1.869181737933218
 1.8535905026598822
 1.853849531185559
 1.8533044510907857
 1.8539603431048204
 1.8505380999059926
 1.8458966749830619
 1.8485879449025375
 1.8466014288404178
 1.8432044580324354
 1.843756916891966
 1.8415707103789285
 1.8422380305170347
 1.8395027306357785
 1.839039767768614
 1.8404470871700418
 1.837951433582401
 1.8310238243098051
 1.828796628841118
 1.8233018274862167
 1.8225635625711887
 1.8232297340457753
 1.8196808049485265
 1.8219308899538686
 1.8152474218492491

julia> W = [2.5035335319008003 -0.6051291288144612 -0.1689777218679678 -0.9139229376292596 -0.040210961009068756 -0.8177789403820881 -1.4387284906035316 -0.11857440768683825 -1.1231036221072999 -0.6762620113091834; -0.09374911691864089 -0.42887981223695043 0.7284972184218675 -0.5670675387158921 0.4167812789732578 -1.5034475118200252 0.9886423898547138 -1.3492365338096244 -0.9750586253661787 -0.8483752221365108; -0.7124302649181368 -0.9167458676376371 2.27465958300614 -0.3032869000938818 -0.18772956846782105 -1.3197127550731036 0.05388676128262615 -1.8090394436392712 -1.0144835155668872 0.9494694186986945; 0.40128723498023444 -0.014084228668655743 1.2716602721419956 -0.9496233115289402 1.4082939719346939 -0.3874304876255929 1.8989409039174776 -1.3745261126856585 -0.9936702313252165 -0.292182064847596; 0.2845984260313545 0.11830021119016007 -0.7757015494761601 1.7071711186968213 -0.7536088314908342 1.9021524469946451 -0.30828491580772593 0.4067420668129639 -0.09633277326280011 0.020316073441156785; 1.0680893116108516 2.660046775251759 -2.7423199895696024 -0.5507438469823729 -0.25137953840767724 -0.2815206218326772 -1.6277312243777011 1.1509955021959797 0.4145348653352118 3.3432201247183664; -0.8737773019904281 -1.056944601887192 0.27269095339178046 0.2985355825572091 2.190549061928218 0.2831634002505407 -0.30999121880830766 0.3723458564897622 2.0118795912737277 0.07771493515557008; -0.8882606274300494 -0.044767409919365495 0.02995063759375047 0.5565480311787793 1.3728530764367048 0.22695066925810886 -0.41772208032587876 1.8710479542474547 -0.04734203599247947 -1.8867372958285409; 0.9084124168648856 -2.228651043649622 -1.0643176249510853 -0.8007436507284191 0.3606469802838978 0.09426944596013466 -0.3129565621241593 -0.4558288073492155 -0.11235836508914612 -0.7470391253456309; 1.1565552274263406 -0.5229422654414112 -0.7350435524831478 -1.0053991489285745 0.10434701963893228 -0.5013587533184336 -0.054385799167590995 0.18866990931032254 1.378690215467587 -1.2596513792048074; 1.4439855585477606 -0.43323493675081565 0.8231218963685216 1.4212259634551225 1.3544331358943218 -0.9705344725556788 0.0015979201868454812 1.228928893560495 -0.6913731322534932 0.4153989968217154; -0.28737252203804564 -0.28278400795859104 1.2411208526105046 1.5522494262634479 1.1388339167211166 -2.5563606982064595 0.24549503930971311 0.09219441260781733 0.33668351394788665 -0.9772842755857244; -0.03589602272954692 0.7567103977508356 -1.7190902969358945 0.03769854052186348 1.7050963711605847 -0.628951168998809 -0.2615952891615254 -0.23987242286688942 0.16167924395683467 -0.5437006990832643; -0.4244315207459674 -0.9405275119609682 0.33431300001664666 0.43420138681892334 0.06010088460481125 1.7223248768609787 -0.1862024622702879 0.32778236128618266 -0.3526329061068121 -0.5146633272778592; -0.3034718621639237 -0.9013703243861266 -0.06282393336525369 0.953620020011297 -1.3599504751226126 -0.11180829178816622 0.46805649789671583 1.1907073417972058 -0.6055094354910646 -0.8928413952165593; 1.5434440708949488 -1.3178377906455692 -0.26854854518833454 2.321942501959965 0.02264940403032524 -1.080762331323439 0.3137691749230393 0.5976947488702328 -1.1954882383535514 -0.04245618319532059; -1.9323517034030346 0.9119918655975101 0.5054491468823874 -0.6706980880689968 0.06931777431379808 -1.5418734383045059 0.6895096945091985 -0.19032098687857843 -1.492901610698006 -0.16634366975408368; 1.4733408930566771 0.8804119329290305 0.22005236525828634 0.2961912515516666 -0.007360219577377495 -0.5276997834969669 -1.0648328437469612 -0.8638639749426833 1.0535591828318407 0.9608882773748826; 2.2137394883328616 0.7821040495206021 0.22047631000810133 -0.35430557227589266 -0.8555229651867147 -0.9686125635058093 1.369597014821592 2.425005905964767 1.5067511278066357 2.574758256926067; -1.360042045537602 -1.1968771724743157 -0.20366772891038631 1.1185873384224911 0.781443253652957 0.5837040210101603 -0.3143927111516672 0.5765788590577331 -1.0160449725294358 -0.1882798481434755; -0.19844359965284755 0.929974468059492 -0.7087603133655928 -1.5957905935882442 1.0668019903504116 -0.4647758405744614 -0.40392335169590865 0.4720673527581623 -0.3201594628491713 0.009001669616913191; -0.19982032073485723 0.9611914599156687 0.5349774547531345 1.185749244318892 -0.7536302391175147 0.438866371576281 -0.7468105442623214 -0.023899980197250762 1.1587993112577324 -0.007864122886505284]
22×10 Matrix{Float64}:
  2.50353    -0.605129   -0.168978   -0.913923   -0.040211    -0.817779   -1.43873     -0.118574   -1.1231     -0.676262
 -0.0937491  -0.42888     0.728497   -0.567068    0.416781    -1.50345     0.988642    -1.34924    -0.975059   -0.848375
 -0.71243    -0.916746    2.27466    -0.303287   -0.18773     -1.31971     0.0538868   -1.80904    -1.01448     0.949469
  0.401287   -0.0140842   1.27166    -0.949623    1.40829     -0.38743     1.89894     -1.37453    -0.99367    -0.292182
  0.284598    0.1183     -0.775702    1.70717    -0.753609     1.90215    -0.308285     0.406742   -0.0963328   0.0203161
  1.06809     2.66005    -2.74232    -0.550744   -0.25138     -0.281521   -1.62773      1.151       0.414535    3.34322
 -0.873777   -1.05694     0.272691    0.298536    2.19055      0.283163   -0.309991     0.372346    2.01188     0.0777149
 -0.888261   -0.0447674   0.0299506   0.556548    1.37285      0.226951   -0.417722     1.87105    -0.047342   -1.88674
  0.908412   -2.22865    -1.06432    -0.800744    0.360647     0.0942694  -0.312957    -0.455829   -0.112358   -0.747039
  1.15656    -0.522942   -0.735044   -1.0054      0.104347    -0.501359   -0.0543858    0.18867     1.37869    -1.25965
  1.44399    -0.433235    0.823122    1.42123     1.35443     -0.970534    0.00159792   1.22893    -0.691373    0.415399
 -0.287373   -0.282784    1.24112     1.55225     1.13883     -2.55636     0.245495     0.0921944   0.336684   -0.977284
 -0.035896    0.75671    -1.71909     0.0376985   1.7051      -0.628951   -0.261595    -0.239872    0.161679   -0.543701
 -0.424432   -0.940528    0.334313    0.434201    0.0601009    1.72232    -0.186202     0.327782   -0.352633   -0.514663
 -0.303472   -0.90137    -0.0628239   0.95362    -1.35995     -0.111808    0.468056     1.19071    -0.605509   -0.892841
  1.54344    -1.31784    -0.268549    2.32194     0.0226494   -1.08076     0.313769     0.597695   -1.19549    -0.0424562
 -1.93235     0.911992    0.505449   -0.670698    0.0693178   -1.54187     0.68951     -0.190321   -1.4929     -0.166344
  1.47334     0.880412    0.220052    0.296191   -0.00736022  -0.5277     -1.06483     -0.863864    1.05356     0.960888
  2.21374     0.782104    0.220476   -0.354306   -0.855523    -0.968613    1.3696       2.42501     1.50675     2.57476
 -1.36004    -1.19688    -0.203668    1.11859     0.781443     0.583704   -0.314393     0.576579   -1.01604    -0.18828
 -0.198444    0.929974   -0.70876    -1.59579     1.0668      -0.464776   -0.403923     0.472067   -0.320159    0.00900167
 -0.19982     0.961191    0.534977    1.18575    -0.75363      0.438866   -0.746811    -0.0239      1.1588     -0.00786412

julia> rbm_qubo = QARBoM.QUBORBM(22,10, W,  DWave.Neal.Optimizer)
QUBORBM(A JuMP Model
Maximization problem with:
Variables: 32
Objective function type: JuMP.QuadExpr
`JuMP.VariableRef`-in-`MathOptInterface.ZeroOne`: 32 constraints
Model mode: AUTOMATIC
CachingOptimizer state: EMPTY_OPTIMIZER
Solver name: D-Wave Neal Simulated Annealing Sampler
Names registered in the model: hid, vis, 22, 10)

julia> 

julia> avg_loss = QARBoM.train_persistent_qubo(rbm_qubo, x_train[1:10000];n_samples = 1, batch_size = 10, n_epochs = 50, learning_rate = 0.01)

Setting mini-batches
Starting training
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     1 |    2.5323 |        3.4178 |     390.0824 |        9.0669 |  402.5671 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     2 |    1.9202 |        2.5833 |     416.4264 |        8.6395 |  830.2164 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     3 |    1.9249 |        2.9217 |     471.3275 |        9.0200 | 1313.4856 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     4 |    1.9638 |        2.9952 |     476.1678 |        8.1788 | 1800.8273 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     5 |    1.9962 |        2.8659 |     449.8775 |        8.7614 | 2262.3321 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     6 |    2.0444 |        2.6139 |     429.1373 |        8.2908 | 2702.3742 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     7 |    2.1265 |        2.6635 |     411.6490 |        8.1237 | 3124.8103 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     8 |    2.2011 |        2.8451 |     394.5018 |        8.1459 | 3530.3031 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     9 |    2.2543 |        2.4080 |     405.8294 |        7.4754 | 3946.0159 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    10 |    2.3068 |        2.2253 |     392.3576 |        7.4404 | 4348.0392 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    11 |    2.3376 |        2.3292 |     384.6255 |        7.4662 | 4742.4601 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    12 |    2.3474 |        2.4317 |     405.5129 |        7.6014 | 5158.0063 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    13 |    2.3765 |        2.2533 |     359.1866 |        7.7527 | 5527.1988 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    14 |    2.4197 |        2.3209 |     426.9877 |        7.8074 | 5964.3149 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    15 |    2.4265 |        2.5597 |     481.9449 |        7.4794 | 6456.2988 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    16 |    2.4341 |        2.6896 |     462.1512 |        7.8788 | 6929.0184 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    17 |    2.4461 |        2.6377 |     476.2045 |        8.1532 | 7416.0138 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    18 |    2.4850 |        2.1943 |     458.4327 |        8.2582 | 7884.8991 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    19 |    2.5379 |        2.5285 |     408.8884 |        7.8768 | 8304.1928 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    20 |    2.6285 |        2.4103 |     429.3110 |        7.8382 | 8743.7523 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    21 |    2.6821 |        2.6462 |     394.0590 |        8.3837 | 9148.8412 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    22 |    2.6915 |        2.7403 |     386.3828 |        8.1048 | 9546.0691 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    23 |    2.6976 |        2.3036 |     378.9567 |        7.8251 | 9935.1546 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    24 |    2.6951 |        2.7880 |     351.4242 |        7.7118 | 10297.0786 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    25 |    2.6977 |        2.4659 |     372.3198 |        7.8561 | 10679.7205 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    26 |    2.7194 |        2.3454 |     387.5939 |        7.6956 | 11077.3553 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    27 |    2.7434 |        2.4004 |     409.4611 |        7.9194 | 11497.1362 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    28 |    2.7841 |        2.5009 |     409.5153 |        7.9928 | 11917.1453 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    29 |    2.8599 |        2.5634 |     425.4705 |        7.6881 | 12352.8672 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    30 |    2.9583 |        2.5622 |     415.2878 |        7.4868 | 12778.2040 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    31 |    3.0391 |        3.0817 |     402.7425 |        7.6725 | 13191.7007 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    32 |    3.1795 |        2.5644 |     426.7101 |        7.7992 | 13628.7744 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    33 |    3.3657 |        2.5036 |     430.8844 |        7.8289 | 14069.9914 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    34 |    3.5830 |        2.7745 |     431.9490 |        7.3462 | 14512.0611 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    35 |    3.6880 |        2.3553 |     422.2850 |        7.6734 | 14944.3748 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    36 |    3.7713 |        2.5924 |     433.2686 |        7.8192 | 15388.0550 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    37 |    3.9261 |        2.3398 |     438.1286 |        8.0952 | 15836.6187 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    38 |    4.0866 |        2.4638 |     453.2552 |        7.7193 | 16300.0570 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    39 |    4.2887 |        2.4506 |     453.7535 |        7.6840 | 16763.9451 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    40 |    4.4184 |        2.5142 |     462.7366 |        7.4604 | 17236.6563 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    41 |    4.4981 |        2.2420 |     461.3917 |        7.7631 | 17708.0531 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    42 |    4.5622 |        2.7407 |     452.9401 |        7.5126 | 18171.2465 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    43 |    4.6320 |        2.5055 |     460.3133 |        7.3798 | 18641.4450 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    44 |    4.6687 |        2.4563 |     447.3854 |        7.9214 | 19099.2080 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    45 |    4.7060 |        2.7370 |     463.6389 |        7.3539 | 19572.9378 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    46 |    4.7489 |        2.8415 |     446.0709 |        7.8798 | 20029.7300 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    47 |    4.7663 |        2.3982 |     446.7006 |        7.9650 | 20486.7938 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    48 |    4.7735 |        2.3997 |     445.0043 |        7.8730 | 20942.0707 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    49 |    4.7772 |        2.6274 |     447.3269 |        7.5621 | 21399.5871 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|    50 |    4.7851 |        2.5177 |     447.5947 |        7.6181 | 21857.3176 |
|------------------------------------------------------------------------------|
Finished training after 50 epochs.
Total time spent sampling: 128.31754183769226
Total time spent in Quantum sampling: 21335.153465270996
Total time spent updating parameters: 393.8465905189514
Total time spent training: 21857.31759762764
50-element Vector{Float64}:
 2.5322740052568187
 1.9202101236600404
 1.924934101572528
 1.9637946784692784
 1.996222105178322
 2.0443803236538813
 2.1264777175307894
 2.201119645757294
 2.254349697593624
 2.3068465718805777
 2.3375835144476156
 2.347447274565023
 2.376522683689439
 2.4197137919848473
 2.4265308251420707
 2.4340747787300048
 2.4461034523090985
 2.4849590559245587
 2.5379226572464773
 2.6284522521912734
 2.6821111744793056
 2.6915058765125264
 2.6976365490904324
 2.6950753702378134
 2.697672230652873
 2.7194129509612073
 2.743444651741858
 2.7841182112410343
 2.859857409411003
 2.9582715859188564
 3.0391442481190234
 3.1794993306920953
 3.3656671412977994
 3.582988619073616
 3.688042805180403
 3.7713461628311924
 3.9261182205296095
 4.086582964568821
 4.2886626375785735
 4.418403034312216
 4.4981388599194325
 4.562181105301543
 4.631980227636198
 4.66872000563792
 4.705993155504649
 4.74885585982439
 4.766279137623814
 4.773450700248769
 4.777215035814357
 4.78512237128263

julia> 

julia> rbm_qubo = QARBoM.QUBORBM(22,10, W,  DWave.Neal.Optimizer)
QUBORBM(A JuMP Model
Minimization problem with:
Variables: 32
Objective function type: JuMP.QuadExpr
`JuMP.VariableRef`-in-`MathOptInterface.ZeroOne`: 32 constraints
Model mode: AUTOMATIC
CachingOptimizer state: EMPTY_OPTIMIZER
Solver name: D-Wave Neal Simulated Annealing Sampler
Names registered in the model: hid, vis, 22, 10)

julia> avg_loss = QARBoM.train_persistent_qubo(rbm_qubo, x_train[1:10000];n_samples = 1, batch_size = 10, n_epochs = 50, learning_rate = 0.01)
Setting mini-batches
Starting training
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     1 |    9.3287 |        3.1482 |     266.6468 |        9.1812 |  278.9762 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     2 |    9.8882 |        2.7193 |     230.4924 |        9.3053 |  521.4933 |
|------------------------------------------------------------------------------|
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     3 |   10.3352 |        3.3583 |     229.0275 |        8.5070 |  762.3861 |
|------------------------------------------------------------------------------|
^CERROR: InterruptException:
Stacktrace:
  [1] Py
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:42 [inlined]
  [2] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:69 [inlined]
  [3] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:76 [inlined]
  [4] pycallargs(f::PythonCall.Core.Py, args::PythonCall.Core.Py, kwargs::PythonCall.Core.Py)
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/builtins.jl:213
  [5] pycall(::PythonCall.Core.Py, ::Dict{…}, ::Vararg{…}; kwargs::@Kwargs{…})
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/builtins.jl:224
  [6] (::PythonCall.Core.Py)(::Dict{…}, ::Vararg{…}; kwargs::@Kwargs{…})
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:339
  [7] macro expansion
    @ ./timing.jl:503 [inlined]
  [8] sample(sampler::DWave.Neal.Optimizer{Float64})
    @ DWave.Neal ~/.julia/packages/DWave/i51VN/src/neal/sampler.jl:57
  [9] macro expansion
    @ ./timing.jl:503 [inlined]
 [10] _sample!(sampler::DWave.Neal.Optimizer{Float64})
    @ QUBODrivers ~/.julia/packages/QUBODrivers/LBuLL/src/interface/sampler.jl:21
 [11] optimize!
    @ ~/.julia/packages/QUBODrivers/LBuLL/src/library/sampler/wrappers/moi.jl:52 [inlined]
 [12] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/MathOptInterface.jl:85 [inlined]
 [13] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:316
 [14] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/Bridges/bridge_optimizer.jl:380 [inlined]
 [15] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:325
 [16] optimize!(model::JuMP.Model; ignore_optimize_hook::Bool, _differentiation_backend::MathOptInterface.Nonlinear.SparseReverseMode, kwargs::@Kwargs{})
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:457
 [17] optimize!(model::JuMP.Model)
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:409
 [18] qubo_sample(rbm::QUBORBM, n_samples::Int64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:60
 [19] persistent_qubo_sampling(rbm::QUBORBM, x::Vector{…}, mini_batches::Vector{…}, n_samples::Int64; learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:117
 [20] persistent_qubo_sampling
    @ ~/Documents/GitHub/RBM/src/qubo_rbm.jl:104 [inlined]
 [21] train_persistent_qubo(rbm::QUBORBM, x_train::Vector{…}; n_epochs::Int64, n_samples::Int64, batch_size::Int64, learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/training.jl:189
Some type information was truncated. Use `show(err)` to see complete types.

julia> rbm_qubo = QARBoM.QUBORBM(22,10, W,  DWave.Neal.Optimizer)
QUBORBM(A JuMP Model
Minimization problem with:
Variables: 32
Objective function type: JuMP.QuadExpr
`JuMP.VariableRef`-in-`MathOptInterface.ZeroOne`: 32 constraints
Model mode: AUTOMATIC
CachingOptimizer state: EMPTY_OPTIMIZER
Solver name: D-Wave Neal Simulated Annealing Sampler
Names registered in the model: hid, vis, 22, 10)

julia> avg_loss = QARBoM.train_persistent_qubo(rbm_qubo, x_train[1:10000];n_samples = 1, batch_size = 10, n_epochs = 50, learning_rate = 0.1)
Setting mini-batches
Starting training
|------------------------------------------------------------------------------|
| Epoch |    MSE    | Time (Sample) | Time (Qsamp) | Time (Update) | Total     |
|------------------------------------------------------------------------------|
|     1 |   10.8476 |        3.1780 |     299.9226 |        9.2221 |  312.3227 |
|------------------------------------------------------------------------------|
^CERROR: InterruptException:
Stacktrace:
  [1] Py
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:42 [inlined]
  [2] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:69 [inlined]
  [3] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:76 [inlined]
  [4] unsafe_pynext
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/builtins.jl:540 [inlined]
  [5] iterate(x::PythonCall.Core.Py, it::PythonCall.Core.Py)
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:324
  [6] iterate
    @ ./iterators.jl:206 [inlined]
  [7] sample(sampler::DWave.Neal.Optimizer{Float64})
    @ DWave.Neal ~/.julia/packages/DWave/i51VN/src/neal/sampler.jl:73
  [8] macro expansion
    @ ./timing.jl:503 [inlined]
  [9] _sample!(sampler::DWave.Neal.Optimizer{Float64})
    @ QUBODrivers ~/.julia/packages/QUBODrivers/LBuLL/src/interface/sampler.jl:21
 [10] optimize!
    @ ~/.julia/packages/QUBODrivers/LBuLL/src/library/sampler/wrappers/moi.jl:52 [inlined]
 [11] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/MathOptInterface.jl:85 [inlined]
 [12] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:316
 [13] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/Bridges/bridge_optimizer.jl:380 [inlined]
 [14] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:325
 [15] optimize!(model::JuMP.Model; ignore_optimize_hook::Bool, _differentiation_backend::MathOptInterface.Nonlinear.SparseReverseMode, kwargs::@Kwargs{})
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:457
 [16] optimize!(model::JuMP.Model)
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:409
 [17] qubo_sample(rbm::QUBORBM, n_samples::Int64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:60
 [18] persistent_qubo_sampling(rbm::QUBORBM, x::Vector{…}, mini_batches::Vector{…}, n_samples::Int64; learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:117
 [19] persistent_qubo_sampling
    @ ~/Documents/GitHub/RBM/src/qubo_rbm.jl:104 [inlined]
 [20] train_persistent_qubo(rbm::QUBORBM, x_train::Vector{…}; n_epochs::Int64, n_samples::Int64, batch_size::Int64, learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/training.jl:189
Some type information was truncated. Use `show(err)` to see complete types.

julia> rbm_qubo = QARBoM.QUBORBM(22,10, W,  DWave.Neal.Optimizer)
QUBORBM(A JuMP Model
Maximization problem with:
Variables: 32
Objective function type: JuMP.QuadExpr
`JuMP.VariableRef`-in-`MathOptInterface.ZeroOne`: 32 constraints
Model mode: AUTOMATIC
CachingOptimizer state: EMPTY_OPTIMIZER
Solver name: D-Wave Neal Simulated Annealing Sampler
Names registered in the model: hid, vis, 22, 10)

julia> avg_loss = QARBoM.train_persistent_qubo(rbm_qubo, x_train[1:10000];n_samples = 1, batch_size = 10, n_epochs = 50, learning_rate = 0.1)
Setting mini-batches
Starting training
total_samples = 1
total_samples = 4
total_samples = 3
total_samples = 6
total_samples = 10
total_samples = 12
total_samples = 13
total_samples = 9
total_samples = 9
total_samples = 10
total_samples = 8
total_samples = 9
total_samples = 10
total_samples = 7
total_samples = 3
total_samples = 9
total_samples = 6
total_samples = 7
total_samples = 4
total_samples = 10
total_samples = 6
total_samples = 8
total_samples = 5
total_samples = 6
total_samples = 7
total_samples = 6
total_samples = 5
total_samples = 9
total_samples = 7
total_samples = 6
total_samples = 8
total_samples = 10
total_samples = 7
total_samples = 8
total_samples = 10
total_samples = 7
total_samples = 8
total_samples = 8
total_samples = 7
total_samples = 11
total_samples = 8
total_samples = 9
total_samples = 5
total_samples = 7
total_samples = 11
total_samples = 9
total_samples = 4
total_samples = 8
total_samples = 7
total_samples = 7
total_samples = 6
total_samples = 11
total_samples = 6
total_samples = 4
total_samples = 6
total_samples = 10
total_samples = 8
total_samples = 6
total_samples = 4
total_samples = 8
total_samples = 4
total_samples = 5
total_samples = 7
total_samples = 5
total_samples = 4
total_samples = 6
total_samples = 5
total_samples = 6
total_samples = 5
total_samples = 7
total_samples = 7
total_samples = 5
total_samples = 5
^CERROR: InterruptException:
Stacktrace:
  [1] Py
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:42 [inlined]
  [2] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:69 [inlined]
  [3] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:76 [inlined]
  [4] pycallargs(f::PythonCall.Core.Py, args::PythonCall.Core.Py, kwargs::PythonCall.Core.Py)
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/builtins.jl:213
  [5] pycall(::PythonCall.Core.Py, ::Dict{…}, ::Vararg{…}; kwargs::@Kwargs{…})
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/builtins.jl:224
  [6] (::PythonCall.Core.Py)(::Dict{…}, ::Vararg{…}; kwargs::@Kwargs{…})
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:339
  [7] macro expansion
    @ ./timing.jl:503 [inlined]
  [8] sample(sampler::DWave.Neal.Optimizer{Float64})
    @ DWave.Neal ~/.julia/packages/DWave/i51VN/src/neal/sampler.jl:57
  [9] macro expansion
    @ ./timing.jl:503 [inlined]
 [10] _sample!(sampler::DWave.Neal.Optimizer{Float64})
    @ QUBODrivers ~/.julia/packages/QUBODrivers/LBuLL/src/interface/sampler.jl:21
 [11] optimize!
    @ ~/.julia/packages/QUBODrivers/LBuLL/src/library/sampler/wrappers/moi.jl:52 [inlined]
 [12] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/MathOptInterface.jl:85 [inlined]
 [13] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:316
 [14] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/Bridges/bridge_optimizer.jl:380 [inlined]
 [15] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:325
 [16] optimize!(model::JuMP.Model; ignore_optimize_hook::Bool, _differentiation_backend::MathOptInterface.Nonlinear.SparseReverseMode, kwargs::@Kwargs{})
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:457
 [17] optimize!(model::JuMP.Model)
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:409
 [18] qubo_sample(rbm::QUBORBM, n_samples::Int64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:60
 [19] persistent_qubo_sampling(rbm::QUBORBM, x::Vector{…}, mini_batches::Vector{…}, n_samples::Int64; learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:118
 [20] persistent_qubo_sampling
    @ ~/Documents/GitHub/RBM/src/qubo_rbm.jl:104 [inlined]
 [21] train_persistent_qubo(rbm::QUBORBM, x_train::Vector{…}; n_epochs::Int64, n_samples::Int64, batch_size::Int64, learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/training.jl:189
Some type information was truncated. Use `show(err)` to see complete types.

julia> rbm_qubo = QARBoM.QUBORBM(22,10, W,  DWave.Neal.Optimizer)
QUBORBM(A JuMP Model
Maximization problem with:
Variables: 32
Objective function type: JuMP.QuadExpr
`JuMP.VariableRef`-in-`MathOptInterface.ZeroOne`: 32 constraints
Model mode: AUTOMATIC
CachingOptimizer state: EMPTY_OPTIMIZER
Solver name: D-Wave Neal Simulated Annealing Sampler
Names registered in the model: hid, vis, 22, 10)

julia> avg_loss = QARBoM.train_persistent_qubo(rbm_qubo, x_train[1:10000];n_samples = 1, batch_size = 10, n_epochs = 50, learning_rate = 0.1)
Setting mini-batches
Starting training
total_samples = 1
total_samples = 3
total_samples = 4
^CERROR: InterruptException:
Stacktrace:
  [1] Py
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:42 [inlined]
  [2] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:69 [inlined]
  [3] pynew
    @ ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:76 [inlined]
  [4] pycallargs(f::PythonCall.Core.Py, args::PythonCall.Core.Py, kwargs::PythonCall.Core.Py)
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/builtins.jl:213
  [5] pycall(::PythonCall.Core.Py, ::Dict{…}, ::Vararg{…}; kwargs::@Kwargs{…})
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/builtins.jl:224
  [6] (::PythonCall.Core.Py)(::Dict{…}, ::Vararg{…}; kwargs::@Kwargs{…})
    @ PythonCall.Core ~/.julia/packages/PythonCall/S5MOg/src/Core/Py.jl:339
  [7] macro expansion
    @ ./timing.jl:503 [inlined]
  [8] sample(sampler::DWave.Neal.Optimizer{Float64})
    @ DWave.Neal ~/.julia/packages/DWave/i51VN/src/neal/sampler.jl:57
  [9] macro expansion
    @ ./timing.jl:503 [inlined]
 [10] _sample!(sampler::DWave.Neal.Optimizer{Float64})
    @ QUBODrivers ~/.julia/packages/QUBODrivers/LBuLL/src/interface/sampler.jl:21
 [11] optimize!
    @ ~/.julia/packages/QUBODrivers/LBuLL/src/library/sampler/wrappers/moi.jl:52 [inlined]
 [12] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/MathOptInterface.jl:85 [inlined]
 [13] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:316
 [14] optimize!
    @ ~/.julia/packages/MathOptInterface/2rAFb/src/Bridges/bridge_optimizer.jl:380 [inlined]
 [15] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{…})
    @ MathOptInterface.Utilities ~/.julia/packages/MathOptInterface/2rAFb/src/Utilities/cachingoptimizer.jl:325
 [16] optimize!(model::JuMP.Model; ignore_optimize_hook::Bool, _differentiation_backend::MathOptInterface.Nonlinear.SparseReverseMode, kwargs::@Kwargs{})
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:457
 [17] optimize!(model::JuMP.Model)
    @ JuMP ~/.julia/packages/JuMP/Gwn88/src/optimizer_interface.jl:409
 [18] qubo_sample(rbm::QUBORBM, n_samples::Int64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:60
 [19] persistent_qubo_sampling(rbm::QUBORBM, x::Vector{…}, mini_batches::Vector{…}, n_samples::Int64; learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/qubo_rbm.jl:118
 [20] persistent_qubo_sampling
    @ ~/Documents/GitHub/RBM/src/qubo_rbm.jl:104 [inlined]
 [21] train_persistent_qubo(rbm::QUBORBM, x_train::Vector{…}; n_epochs::Int64, n_samples::Int64, batch_size::Int64, learning_rate::Float64)
    @ QARBoM ~/Documents/GitHub/RBM/src/training.jl:189
Some type information was truncated. Use `show(err)` to see complete types.

julia> rbm_qubo = QARBoM.QUBORBM(22,10, W,  DWave.Neal.Optimizer)
QUBORBM(A JuMP Model
Maximization problem with:
Variables: 32
Objective function type: JuMP.QuadExpr
`JuMP.VariableRef`-in-`MathOptInterface.ZeroOne`: 32 constraints
Model mode: AUTOMATIC
CachingOptimizer state: EMPTY_OPTIMIZER
Solver name: D-Wave Neal Simulated Annealing Sampler
Names registered in the model: hid, vis, 22, 10)

julia> avg_loss = QARBoM.train_persistent_qubo(rbm_qubo, x_train[1:10000];n_samples = 1, batch_size = 10, n_epochs = 50, learning_rate = 0.1)
Setting mini-batches
Starting training

